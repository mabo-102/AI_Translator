import asyncio
import os
import queue
import tempfile
import threading
import logging

from faster_whisper import WhisperModel
import numpy as np
from scipy.io.wavfile import write
import sounddevice as sd

# ==== ãƒ­ã‚°è¨­å®š ====
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ==== ãƒ¢ãƒ‡ãƒ«é¸æŠ ====
MODEL_LIST = {
    "1": "tiny",
    "2": "small",
    "3": "medium",
    "4": "large-v2",
    "5": "large-v3",
    "6": "deepdml/faster-whisper-large-v3-turbo-ct2",
}

print("ãƒ¢ãƒ‡ãƒ«é¸æŠï¼š")
for k, v in MODEL_LIST.items():
    print(f"{k}: {v}")
model_key = input("ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
model_name = MODEL_LIST.get(model_key, "tiny")
logging.info(f"ãƒ¢ãƒ‡ãƒ«: {model_name} ã‚’ä½¿ç”¨")
model = WhisperModel(model_name, device="cuda", compute_type="float16")

# ==== éŸ³å£°è¨­å®š ====
SAMPLERATE = 16000
CHUNK_DURATION = 0.5  # ç§’
CHUNK_SIZE = int(SAMPLERATE * CHUNK_DURATION)
CHANNELS = 1

# ==== ç„¡éŸ³æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ====
SILENT_THRESHOLD = 5  # RMS
SPEECH_START_THRESHOLD = 50  # è©±ã—å§‹ã‚ã®RMS
MAX_SILENCE_CHUNKS = 4  # ç„¡éŸ³ãŒç¶šã„ãŸã‚‰è©±ã—çµ‚ã‚ã‚Šã¨åˆ¤æ–­

# ==== Queue ====
record_queue = queue.Queue()

# ==== çŠ¶æ…‹ç®¡ç† ====
speaking = False
silence_chunks = 0
buffer = []
last_rms = 0

# ==== éŸ³å£°å‡¦ç†é–¢æ•° ====
def is_silent(chunk):
    rms = np.sqrt(np.mean(chunk.astype(np.float32) ** 2))
    return rms < SILENT_THRESHOLD

def has_started_speaking(chunk):
    global last_rms
    rms = np.sqrt(np.mean(chunk.astype(np.float32) ** 2))
    triggered = rms > SPEECH_START_THRESHOLD and last_rms < SPEECH_START_THRESHOLD
    last_rms = rms
    return triggered

def process_audio(chunks):
    logging.info("ğŸ” èªè­˜ä¸­...")
    audio_np = np.concatenate(chunks, axis=0)
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
        write(tmp.name, SAMPLERATE, audio_np)
        tmp_path = tmp.name

    segments, _ = model.transcribe(tmp_path, language="ja", vad_filter=True)
    for seg in segments:
        print(f"[{seg.start:.1f}s â†’ {seg.end:.1f}s] {seg.text.strip()}")

    os.remove(tmp_path)

# ==== éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰ ====
def record_stream():
    def callback(indata, frames, time_info, status):
        if status:
            logging.warning(f"[!] Status: {status}")
        record_queue.put(indata.copy())

    with sd.InputStream(callback=callback, samplerate=SAMPLERATE,
                        blocksize=CHUNK_SIZE, channels=CHANNELS, dtype='int16'):
        while True:
            sd.sleep(100)

# ==== ãƒ¡ã‚¤ãƒ³å‡¦ç† ====
async def main_loop():
    global speaking, silence_chunks, buffer
    print("ğŸ™ï¸ éŸ³å£°å…¥åŠ›å¾…æ©Ÿä¸­... (Ctrl+Cã§çµ‚äº†)")

    while True:
        chunk = await asyncio.to_thread(record_queue.get)

        if has_started_speaking(chunk) and not speaking:
            logging.info("ğŸ¤ è©±ã—å§‹ã‚ã‚’æ¤œå‡º")
            speaking = True
            buffer = [chunk]
            silence_chunks = 0
        elif speaking:
            buffer.append(chunk)
            if is_silent(chunk):
                silence_chunks += 1
                if silence_chunks >= MAX_SILENCE_CHUNKS:
                    logging.info("ğŸ›‘ è©±ã—çµ‚ã‚ã‚Š â†’ æ–‡å­—èµ·ã“ã—")
                    await asyncio.to_thread(process_audio, buffer)
                    speaking = False
                    buffer = []
            else:
                silence_chunks = 0

# ==== ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ====
async def main():
    threading.Thread(target=record_stream, daemon=True).start()
    await main_loop()

try:
    asyncio.run(main())
except KeyboardInterrupt:
    print("\nğŸ›‘ åœæ­¢ã—ã¾ã—ãŸã€‚")
